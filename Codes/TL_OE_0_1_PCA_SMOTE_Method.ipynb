{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TL_OE_0/1_PCA_SMOTE_Method.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4flEcnCUFdnF"
      },
      "source": [
        "#Import Data\n",
        "I will drop this comment later.\n",
        "\n",
        "Here, Professor, I reduced the size of the two datasets because the performance of classical supervised methods (Without TL) is so high and it is so difficult to see an improvement with TL.\n",
        "\n",
        "By reducing the size of the datasets I obtained a target model with acceptable performance and by using TL the performance of the model *increased* significantly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj-OB1lsWlVR"
      },
      "source": [
        "import pandas as pd\n",
        "Final_Data_S1 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S1.csv\")\n",
        "Final_Data_S2 = pd.read_csv(\"/content/drive/MyDrive/Final_Data_S2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsBU5L61Wx_R"
      },
      "source": [
        "Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([3.0, 4.0])].index,'labels']=2.0\n",
        "Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([3.0, 4.0])].index,'labels']=2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6_0ysRISxXF"
      },
      "source": [
        "Data_0 = Final_Data_S1[Final_Data_S1.labels == 0].iloc[:386]\n",
        "Data_1 = Final_Data_S1[Final_Data_S1.labels == 1].iloc[:95]\n",
        "Data_2 = Final_Data_S1[Final_Data_S1.labels == 2].iloc[:52]\n",
        "frames = [Data_0, Data_1, Data_2]\n",
        "Final_Data_S1 = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ysjuIbo-vSt"
      },
      "source": [
        "Data_0 = Final_Data_S2[Final_Data_S2.labels == 0].iloc[:772]\n",
        "Data_1 = Final_Data_S2[Final_Data_S2.labels == 1].iloc[:190]\n",
        "Data_2 = Final_Data_S2[Final_Data_S2.labels == 2].iloc[:104]\n",
        "frames = [Data_0, Data_1, Data_2]\n",
        "Final_Data_S2 = pd.concat(frames)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33VWXOhh3vgH"
      },
      "source": [
        "Final_Data_S1.loc[Final_Data_S1[Final_Data_S1.labels.isin([2.0])].index,'labels']=1.0\n",
        "Final_Data_S2.loc[Final_Data_S2[Final_Data_S2.labels.isin([2.0])].index,'labels']=1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1oaAJ4XFj9s"
      },
      "source": [
        "#Class Transformation\n",
        "We created a PCA-SMOTE transformation for the source and for the target datasets to transform the data into a new common feature space."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFxHgDCTkWy_"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.decomposition import PCA\n",
        "np.random.seed(2)\n",
        "!pip install imbalanced-learn\n",
        "from imblearn.over_sampling import SMOTE \n",
        "\n",
        "labels_S1 = Final_Data_S2.labels\n",
        "labels_S2 = Final_Data_S1.labels\n",
        "Data_S1 = Final_Data_S2.drop(['time', 'labels'], axis= 1)\n",
        "Data_S2 = Final_Data_S1.drop(['time', 'labels'], axis= 1)\n",
        "pca = PCA(n_components=7)\n",
        "principalComponents_S1 = pca.fit_transform(Data_S1)\n",
        "pca = PCA(n_components=6)\n",
        "principalComponents_S2 = pca.fit_transform(Data_S2)\n",
        "\n",
        "sm = SMOTE(random_state=7)\n",
        "principalComponents_S1, labels_S1 = sm.fit_resample(principalComponents_S1, labels_S1)\n",
        "principalComponents_S2, labels_S2 = sm.fit_resample(principalComponents_S2, labels_S2)\n",
        "\n",
        "principalComponents_S1 = pd.DataFrame(principalComponents_S1)\n",
        "principalComponents_S2 = pd.DataFrame(principalComponents_S2)\n",
        "\n",
        "\n",
        "labels_S1 = pd.Series(labels_S1)\n",
        "labels_S2 = pd.Series(labels_S2)\n",
        "\n",
        "principalComponents_S1.columns = ['pc_Source_' + str(i) for i in range(1, 8)]\n",
        "principalComponents_S2.columns = ['pc_Target_' + str(i) for i in range(1, 7)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWggpp-OF_Ru"
      },
      "source": [
        "#Class Divergence_Calculation\n",
        "We calculated the divergence between features from source and target datasets using the JSD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUBKpaIzk9Q3"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from scipy.spatial import distance\n",
        "\n",
        "class Divergence_Calculation:\n",
        "\n",
        "  def add_target(self, Final_Data, labels):\n",
        "    Final_Data['labels'] = labels.values\n",
        "    return Final_Data\n",
        "\n",
        "  def prob_dist_divergence_initial(self, data, num_pc, name):\n",
        "\n",
        "    results = data\n",
        "    column = ['pc_'+ name + '_' + str(i) for i in range(1,num_pc+1)]\n",
        "    res = pd.DataFrame(data = np.zeros((5,1)), columns=['None'])\n",
        "    \n",
        "    for i in column:\n",
        "      table = pd.DataFrame(data = np.zeros((5,2)), \\\n",
        "                           columns= [i+'0', i+'1'])\n",
        "      condit = pd.DataFrame(data = results.groupby('labels')[i])\n",
        "      for j in range(2):\n",
        "        x = condit.iloc[j,1]\n",
        "        table.iloc[:,j] = np.histogram(x, bins = 5)[0] / len(x)   \n",
        "      res = pd.concat([res, table], axis=1)\n",
        "\n",
        "    return res\n",
        "\n",
        "  \n",
        "  def jsd_final(self, X1_Source_init,X2_Target_init, Final_Data_Target):\n",
        "\n",
        "    target_prob = Final_Data_Target.labels.value_counts()/len(Final_Data_Target)\n",
        "    matrix = pd.DataFrame(data = np.zeros((Final_Data_Source.shape[1]-1, Final_Data_Target.shape[1]-1)))\n",
        "    matrix.columns = [i for i in Final_Data_Target.columns if i!= 'labels']\n",
        "    matrix.index = [i for i in Final_Data_Source.columns if i != 'labels']\n",
        "      \n",
        "    for i in matrix.columns:\n",
        "      for j in matrix.index:\n",
        "        matrix.loc[j,i] = sum([target_prob.loc[target_prob.index == k].\\\n",
        "          values[0]*distance.jensenshannon(X1_Source_init[j+str(int(k))], X2_Target_init[i+str(int(k))], 2.0) for k in target_prob.index])\n",
        "    return matrix\n",
        "\n",
        "#script\n",
        "divergence_calculation = Divergence_Calculation()\n",
        "Final_Data_Source = divergence_calculation.add_target(principalComponents_S1, labels_S1)\n",
        "Final_Data_Target = divergence_calculation.add_target(principalComponents_S2, labels_S2)\n",
        "\n",
        "X1_Source_init = divergence_calculation.prob_dist_divergence_initial(Final_Data_Source, 7, 'Source')\n",
        "X2_Target_init = divergence_calculation.prob_dist_divergence_initial(Final_Data_Target, 6, 'Target')\n",
        "\n",
        "divergence_matrix = divergence_calculation.jsd_final(X1_Source_init,X2_Target_init, Final_Data_Target)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po2BqDC1GCbO"
      },
      "source": [
        "#Class PreMapping\n",
        "We used Thresholidng to avoid negative transfer and we created the Preferences lists for the mapping procedure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmEE1-bGp2Bf"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "class PreMapping:\n",
        "\n",
        "  def threshold_select(self, divergence_matrix, threshold):\n",
        "    divergence_matrix_bool = divergence_matrix > threshold\n",
        "    indx = []\n",
        "\n",
        "    for j in range(divergence_matrix.shape[1]):\n",
        "      Test = True\n",
        "      for i in range(len(divergence_matrix)):\n",
        "        if divergence_matrix_bool.iloc[i,j] == False:\n",
        "          Test = False\n",
        "      if Test == True:\n",
        "        indx.append(j)\n",
        "\n",
        "    new_indx = [i for i in range(divergence_matrix.shape[1]) if i not in indx]\n",
        "    divergence_matrix = divergence_matrix.iloc[:,new_indx]\n",
        "    return divergence_matrix\n",
        "\n",
        "  def preferences(self, divergence_matrix):\n",
        "    Source_features = [i for i in divergence_matrix.index]\n",
        "    Target_features = [i for i in divergence_matrix.columns]\n",
        "\n",
        "    priority_source = {i:list(divergence_matrix.loc[i,:].sort_values().index) for i in Source_features}\n",
        "    priority_target = {i:list(divergence_matrix.loc[:,i].sort_values().index) for i in Target_features}\n",
        "\n",
        "    return priority_source, priority_target\n",
        "\n",
        "#script\n",
        "preMapping = PreMapping()\n",
        "#divergence_matrix = preMapping.threshold_select(divergence_matrix, 0.37)\n",
        "priority_source, priority_target = preMapping.preferences(divergence_matrix)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbaT5yTqGFLe"
      },
      "source": [
        "#Class Mapping\n",
        "We applied the Gale-Shapley Algorithm to map features from both domains based on their divergence values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-ZIfzNvp_vZ"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from collections import defaultdict\n",
        "class Mapping:\n",
        "\n",
        "    def __init__(self, men, women):\n",
        "        '''\n",
        "        Constructs a Matcher instance.\n",
        "        Takes a dict of men's spousal preferences, `men`,\n",
        "        and a dict of women's spousal preferences, `women`.\n",
        "        '''\n",
        "        self.M = men\n",
        "        self.W = women\n",
        "        self.wives = {}\n",
        "        self.pairs = []\n",
        "\n",
        "        # we index spousal preferences at initialization \n",
        "        # to avoid expensive lookups when matching\n",
        "        self.mrank = defaultdict(dict)  # `mrank[m][w]` is m's ranking of w\n",
        "        self.wrank = defaultdict(dict)  # `wrank[w][m]` is w's ranking of m\n",
        "\n",
        "        for m, prefs in men.items():\n",
        "            for i, w in enumerate(prefs):\n",
        "                self.mrank[m][w] = i\n",
        "\n",
        "        for w, prefs in women.items():\n",
        "            for i, m in enumerate(prefs):\n",
        "                self.wrank[w][m] = i\n",
        "\n",
        "\n",
        "    def __call__(self):\n",
        "        return self.match()\n",
        "\n",
        "    def prefers(self, w, m, h):\n",
        "        '''Test whether w prefers m over h.'''\n",
        "        return self.wrank[w][m] < self.wrank[w][h]\n",
        "\n",
        "    def after(self, m, w):\n",
        "        '''Return the woman favored by m after w.'''\n",
        "        i = self.mrank[m][w] + 1    # index of woman following w in list of prefs\n",
        "        return self.M[m][i]\n",
        "\n",
        "    def match(self, men=None, next=None, wives=None):\n",
        "        '''\n",
        "        Try to match all men with their next preferred spouse.\n",
        "        \n",
        "        '''\n",
        "        if men is None: \n",
        "            men = self.M.keys()         # get the complete list of men\n",
        "        if next is None: \n",
        "            # if not defined, map each man to their first preference\n",
        "            next = dict((m, rank[0]) for m, rank in self.M.items()) \n",
        "        if wives is None: \n",
        "            wives = {}                  # mapping from women to current spouse\n",
        "        if not len(men): \n",
        "            self.pairs = [(h, w) for w, h in wives.items()]\n",
        "            self.wives = wives\n",
        "            return wives\n",
        "        m, men = list(men)[0], list(men)[1:]\n",
        "        w = next[m]                     # next woman for m to propose to\n",
        "        next[m] = self.after(m, w)      # woman after w in m's list of prefs\n",
        "        if w in wives:\n",
        "            h = wives[w]                # current husband\n",
        "            if self.prefers(w, m, h):\n",
        "                men.append(h)           # husband becomes available again\n",
        "                wives[w] = m            # w becomes wife of m\n",
        "            else:\n",
        "                men.append(m)           # m remains unmarried\n",
        "        else:\n",
        "            wives[w] = m                # w becomes wife of m\n",
        "        return self.match(men, next, wives)\n",
        "\n",
        "    def map_source(self, Final_Data_Source, Final_Data_Target, Final_Match):\n",
        "\n",
        "      Final_Data_Source = Final_Data_Source.rename(columns=Final_Match)\n",
        "      Final_Data_Source = Final_Data_Source[Final_Data_Target.columns]\n",
        "      return Final_Data_Source\n",
        "\n",
        "#script\n",
        "mapping = Mapping(priority_target, priority_source)\n",
        "Final_Match = mapping.match()\n",
        "Final_Data_Target = Final_Data_Target[list(Final_Match.values()) + ['labels']]\n",
        "Final_Data_Source = mapping.map_source(Final_Data_Source, Final_Data_Target, Final_Match)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0QDpGzdGIM2"
      },
      "source": [
        "#Class PostMapping\n",
        "We added target data in the training to enhance the performance of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2gjuL9vqCEg"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "class PostMapping:\n",
        "\n",
        "  def shuffle_data(self, Final_Data):\n",
        "    Final_Data = Final_Data.sample(frac = 1)\n",
        "    return Final_Data\n",
        "\n",
        "  def rearrage_data(self, Final_Data_Source, Final_Data_Target, number_rows):\n",
        "    add_data = Final_Data_Target.iloc[:number_rows,:]\n",
        "    Final_Data_Target = Final_Data_Target.iloc[number_rows:,:]\n",
        "    frames = [Final_Data_Source, add_data]\n",
        "    Final_Data_Source = pd.concat(frames)\n",
        "\n",
        "    return Final_Data_Source, Final_Data_Target\n",
        "\n",
        "\n",
        "#script\n",
        "postMapping = PostMapping()\n",
        "Final_Data_Source = postMapping.shuffle_data(Final_Data_Source)\n",
        "Final_Data_Target = postMapping.shuffle_data(Final_Data_Target)\n",
        "Data_Target = Final_Data_Target\n",
        "# Target data added in the training\n",
        "# 0 days = 0\n",
        "# 2 days = 257\n",
        "# 4 days = 515\n",
        "Final_Data_Source, Final_Data_Target = postMapping.rearrage_data(Final_Data_Source, Final_Data_Target, 515)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhzHq23_GPqN"
      },
      "source": [
        "#Class Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gz-_int3qOqv",
        "outputId": "80f5aee3-8d0e-4554-b279-95949ae38315"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "class Modeling:\n",
        "\n",
        "  def split_train_test(self, Final_Data_Source, Final_Data_Target):\n",
        "    X_train = Final_Data_Source.drop(['labels'], axis=1)\n",
        "    y_train = Final_Data_Source['labels']\n",
        "    X_test = Final_Data_Target.drop(['labels'], axis=1)\n",
        "    y_test = Final_Data_Target['labels']\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "  def split_train_val(self, X, y):    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.35, random_state=42)\n",
        "    return X_train, X_val, y_train, y_val\n",
        "\n",
        "  def pipelines_def(self):\n",
        "    pipelines = []\n",
        "    params = []\n",
        "    names = []\n",
        "    #Notice that we tried to balance the data via using the clf__class_weight parameter in the models\n",
        "\n",
        "    pipelines.append(Pipeline([('clf', DecisionTreeClassifier())])) ## DecisionTreeClassifier\n",
        "    params.append({'clf__max_features': [None], 'clf__min_samples_split': [2], 'clf__min_samples_leaf':[1],\n",
        "                  'clf__class_weight': ['balanced']})\n",
        "    names.append('DecisionTreeClassifier') \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return pipelines, params, names\n",
        "\n",
        "  def model(self, pipeline, param, name, X, y):    \n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=32)\n",
        "\n",
        "    grid_obj = GridSearchCV(estimator=pipeline, param_grid=param, cv=cv, scoring='f1_micro', n_jobs=-1)\n",
        "    grid_obj.fit(X,y)  \n",
        "\n",
        "    print(name, 'F1-measure:', grid_obj.best_score_)\n",
        "    estimator = grid_obj.best_estimator_\n",
        "    estimator.fit(X,y) # train on all training dataset\n",
        "    return estimator \n",
        "\n",
        "\n",
        "  def estimators(self, pipelines, params, names,  X_train, y_train):\n",
        "    estimators = []\n",
        "    for idx in range(0,len(pipelines)):    \n",
        "        estimators.append(self.model(pipelines[idx], params[idx], names[idx], X_train, y_train))\n",
        "    return estimators\n",
        "\n",
        "\n",
        "  def evaluate_models(self,estimators, names, X_test, y_test):\n",
        "   \n",
        "    for idx, estimator in enumerate(estimators):\n",
        "      print('\\nPerformance of', names[idx])\n",
        "      y_pred = estimator.predict(X_test)       \n",
        "      print('\\nConfusion matrix\\n', confusion_matrix(y_test, y_pred), '\\n')    \n",
        "      print('F1-measure', f1_score(y_test, y_pred, average='micro'), '\\n')\n",
        "\n",
        "      precision, recall, fscore, support = score(y_test, y_pred)\n",
        "\n",
        "      print('precision: {}'.format(precision))\n",
        "      print('recall: {}'.format(recall))\n",
        "      print('fscore: {}'.format(fscore))\n",
        "      print('support: {}'.format(support))\n",
        "\n",
        "    return\n",
        "\n",
        "#script\n",
        "modeling = Modeling()\n",
        "\n",
        "X_train, y_train, X_test, y_test = modeling.split_train_test(Final_Data_Source, Final_Data_Target)\n",
        "X_test_T, y_test_T, X_test_T, y_test_T = modeling.split_train_test(Data_Target, Data_Target)\n",
        "X_train_S,  X_test_S, y_train_S, y_test_S = modeling.split_train_val(X_test_T, y_test_T                                                                  \n",
        "                                                                     )\n",
        "pipelines, params, names = modeling.pipelines_def()\n",
        "print('Source Training results_without TL')\n",
        "estimators = modeling.estimators(pipelines, params, names, X_train_S, y_train_S)\n",
        "print('Source Testing results_without TL')\n",
        "modeling.evaluate_models(estimators, names, X_test_S, y_test_S)\n",
        "\n",
        "\n",
        "print('Training results_TL')\n",
        "estimators = modeling.estimators(pipelines, params, names, X_train, y_train)\n",
        "print('Testing results_TL')\n",
        "modeling.evaluate_models(estimators, names, X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Training results_without TL\n",
            "DecisionTreeClassifier F1-measure: 0.8960784313725491\n",
            "Source Testing results_without TL\n",
            "\n",
            "Performance of DecisionTreeClassifier\n",
            "\n",
            "Confusion matrix\n",
            " [[115  17]\n",
            " [  7 132]] \n",
            "\n",
            "F1-measure 0.9114391143911439 \n",
            "\n",
            "precision: [0.94262295 0.88590604]\n",
            "recall: [0.87121212 0.94964029]\n",
            "fscore: [0.90551181 0.91666667]\n",
            "support: [132 139]\n",
            "Training results_TL\n",
            "DecisionTreeClassifier F1-measure: 0.9407459152261426\n",
            "Testing results_TL\n",
            "\n",
            "Performance of DecisionTreeClassifier\n",
            "\n",
            "Confusion matrix\n",
            " [[109   8]\n",
            " [ 13 127]] \n",
            "\n",
            "F1-measure 0.9182879377431906 \n",
            "\n",
            "precision: [0.89344262 0.94074074]\n",
            "recall: [0.93162393 0.90714286]\n",
            "fscore: [0.91213389 0.92363636]\n",
            "support: [117 140]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APFUF3X1qR_X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}