{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple_Feature_Matching_TL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgZgV-omQJ8B"
      },
      "source": [
        "#Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcEsDivdQOPh"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score \n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "Final_Data_Source = pd.read_csv(\"/content/drive/MyDrive/Final_Data_Source.csv\")\n",
        "Final_Data_Target = pd.read_csv(\"/content/drive/MyDrive/Final_Data_Target.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT9gwh_QQT5g"
      },
      "source": [
        "#Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHETNjs3Qfqx"
      },
      "source": [
        "np.random.seed(32)\n",
        "Final_Data_Source.labels = Final_Data_Source.labels.round()\n",
        "Final_Data_Source.loc[Final_Data_Source[Final_Data_Source.labels.isin([3.0])].index,'labels']=2.0\n",
        "Final_Data_Source.loc[Final_Data_Source[Final_Data_Source.labels.isin([4.0])].index,'labels']=2.0\n",
        "Final_Data_Source.sum_power = Final_Data_Source.sum_power/5\n",
        "Final_Data_Source.drop(['power1', 'power2', 'power3', 'power5','power6', 'window'], axis= 1, inplace= True)\n",
        "\n",
        "\n",
        "Final_Data_Target.drop(['power1', 'power2', 'power3', 'power4'], axis= 1, inplace= True)\n",
        "Final_Data_Target.sum_power = Final_Data_Target.sum_power/4\n",
        "Final_Data_Target.columns = ['time', 'co2', 'Door_contact','rms', 'motion', 'labels', 'sum_power', \n",
        "       'derivative_co2']\n",
        "Final_Data_Target.loc[Final_Data_Target[Final_Data_Target.labels.isin([3.0])].index,'labels']=2.0\n",
        "Final_Data_Target.loc[Final_Data_Target[Final_Data_Target.labels.isin([4.0])].index,'labels']=2.0\n",
        "Final_Data_Source = Final_Data_Source[Final_Data_Target.columns]\n",
        "\n",
        "Final_Data_Target = Final_Data_Target.sample(frac=1)\n",
        "Final_Data_Source = Final_Data_Source.sample(frac=1)\n",
        "\n",
        "F_Train = Final_Data_Target.iloc[:1 ,:]\n",
        "F_Test = Final_Data_Target.iloc[1 :,:]\n",
        "\n",
        "frames = [F_Train, Final_Data_Source]\n",
        "F_Train = pd.concat(frames)\n",
        "Final_Data_Source = F_Train.sample(frac=1)\n",
        "\n",
        "y_train_T = Final_Data_Target.labels\n",
        "X_train_T = Final_Data_Target.drop(['labels', 'time'], axis= 1)\n",
        "\n",
        "y_train_S = Final_Data_Source.labels\n",
        "X_train_S = Final_Data_Source.drop(['labels', 'time'], axis= 1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkNTWgZoTT81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9300f40d-b637-4139-8011-8919019a3cb9"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_train_T, y_train_T, test_size=0.35)\n",
        "pipelines = []\n",
        "params = []\n",
        "names = []\n",
        "pipelines.append(Pipeline([('clf', DecisionTreeClassifier())])) ## DecisionTreeClassifier\n",
        "params.append({'clf__max_features': [None], 'clf__min_samples_split': [2], 'clf__min_samples_leaf':[1],\n",
        "              'clf__class_weight': ['balanced']})\n",
        "names.append('DecisionTreeClassifier') \n",
        "\n",
        "\n",
        " \n",
        "def model(pipeline, parameters, name, X, y):    \n",
        "    cv = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "    grid_obj = GridSearchCV(estimator=pipeline, param_grid=parameters, cv=cv, scoring='f1_micro', n_jobs=-1)\n",
        "    grid_obj.fit(X,y)  \n",
        "\n",
        "    print(name, 'F1-measure:', grid_obj.best_score_)\n",
        "    estimator = grid_obj.best_estimator_\n",
        "    estimator.fit(X,y) # train on all training dataset\n",
        "    return estimator \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_models(estimators, names, X_test, y_test):\n",
        "    \n",
        "    for idx, estimator in enumerate(estimators):\n",
        "      try:\n",
        "\n",
        "        print('\\nPerformance of', names[idx])\n",
        "        \n",
        "        y_pred = estimator.predict(X_test)       \n",
        "        print('\\nConfusion matrix\\n', confusion_matrix(y_test, y_pred), '\\n')    \n",
        "        print('F1-measure', f1_score(y_test, y_pred, average='micro'), '\\n') \n",
        "        precision, recall, fscore, support = score(y_test, y_pred)\n",
        "\n",
        "        print('precision: {}'.format(precision))\n",
        "        print('recall: {}'.format(recall))\n",
        "        print('fscore: {}'.format(fscore))\n",
        "        print('support: {}'.format(support))   \n",
        "      except:\n",
        "        continue\n",
        "print('Target results without TL:')\n",
        "estimators = []\n",
        "for idx in range(0,len(pipelines)):    \n",
        "    estimators.append(model(pipelines[idx], params[idx], names[idx], X_train, y_train))        \n",
        "evaluate_models(estimators, names, X_test.values, y_test.values.reshape(-1,1))\n",
        "\n",
        "\n",
        "print('Target results with TL:')\n",
        "estimators = []\n",
        "for idx in range(0,len(pipelines)):    \n",
        "    estimators.append(model(pipelines[idx], params[idx], names[idx], X_train_S, y_train_S))        \n",
        "evaluate_models(estimators, names, X_test.values, y_test.values.reshape(-1,1))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target results without TL:\n",
            "DecisionTreeClassifier F1-measure: 0.8994073748902546\n",
            "\n",
            "Performance of DecisionTreeClassifier\n",
            "\n",
            "Confusion matrix\n",
            " [[254   8   3]\n",
            " [  6  44  11]\n",
            " [  1  10  28]] \n",
            "\n",
            "F1-measure 0.8931506849315068 \n",
            "\n",
            "precision: [0.97318008 0.70967742 0.66666667]\n",
            "recall: [0.95849057 0.72131148 0.71794872]\n",
            "fscore: [0.96577947 0.71544715 0.69135802]\n",
            "support: [265  61  39]\n",
            "Target results with TL:\n",
            "DecisionTreeClassifier F1-measure: 0.9496274217585693\n",
            "\n",
            "Performance of DecisionTreeClassifier\n",
            "\n",
            "Confusion matrix\n",
            " [[222  18  25]\n",
            " [ 58   1   2]\n",
            " [ 36   1   2]] \n",
            "\n",
            "F1-measure 0.6164383561643836 \n",
            "\n",
            "precision: [0.70253165 0.05       0.06896552]\n",
            "recall: [0.83773585 0.01639344 0.05128205]\n",
            "fscore: [0.76419966 0.02469136 0.05882353]\n",
            "support: [265  61  39]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5oZTR2WUVXl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}